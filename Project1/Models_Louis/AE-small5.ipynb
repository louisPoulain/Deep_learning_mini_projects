{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AE-small5.ipynb","provenance":[],"mount_file_id":"1LMu3GW0aO36sZWSsuAduw6Sj7Qmgno4z","authorship_tag":"ABX9TyNNccZgF1oN2Bfbil9fgNpa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"X4rdiLd1ZaDm","colab":{"base_uri":"https://localhost:8080/","height":606},"executionInfo":{"status":"error","timestamp":1651927509896,"user_tz":-120,"elapsed":243976,"user":{"displayName":"Louis Poulain","userId":"00408241798532179809"}},"outputId":"584948c1-c519-4b0c-f816-22fb7982b4d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n","Training data : \n"," noisy_imgs_1 :  torch.Size([50000, 3, 32, 32]) \n"," noisy_imgs_2 :  torch.Size([50000, 3, 32, 32])\n","Data reduced : \n"," noisy_imgs_1_reduced :  torch.Size([50000, 3, 32, 32]) \n"," noisy_imgs_2_reduced :  torch.Size([50000, 3, 32, 32])\n","Type :  torch.uint8\n","epoch :  1\n","The epoch took 172.51156401634216s to complete\n","\n","epoch :  2\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-97fca311b7d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;31m# .step() performs parameter update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# Storing the losses in a list for plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Wed Apr 27 15:43:57 2022\n","\n","@author: louis\n","\"\"\"\n","\"file for colab\"\n","import torch \n","# import torch.nn.functional as F\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","\n","def psnr(denoised, ground_truth):\n","    # Peak Signal to Noise Ratio: denoised and ground Ì‡truth have range [0, 1]\n","    mse = torch.mean((denoised - ground_truth) ** 2)\n","    return -10 * torch.log10(mse + 10**-8)\n","\n","class Dataset(torch.utils.data.Dataset):\n","  'Characterizes a dataset for PyTorch'\n","  def __init__(self, SIZE, train = True):\n","        'Initialization'\n","        if train: \n","            x, y = torch.load(\"drive/MyDrive/Colab_Notebooks/DeepL_miniProj/train_data.pkl\")\n","            print(\"Training data : \\n noisy_imgs_1 : \", x.shape, \"\\n noisy_imgs_2 : \", y.shape)\n","            if SIZE > 50000:\n","                print(\"You entered a size too big, using size = 50000\")\n","                SIZE = 50000\n","        else : \n","            x, y = torch.load(\"drive/MyDrive/Colab_Notebooks/DeepL_miniProj/val_data.pkl\")\n","            print(\"Test data : \\n noisy_imgs : \", x.shape, \"\\n clean_imgs : \", y.shape)\n","            if SIZE > 50000:\n","                print(\"You entered a size too big, using size = 1000\")\n","                SIZE = 1000\n","        x, y = x[:SIZE], y[:SIZE]\n","        print(\"Data reduced : \\n noisy_imgs_1_reduced : \", x.shape, \"\\n noisy_imgs_2_reduced : \", y.shape)\n","        print(\"Type : \", x.dtype)\n","        self.x = x.float()\n","        self.y = y.float()\n","\n","  def __len__(self):\n","        'Denotes the total number of samples'\n","        return len(self.x)\n","\n","  def __getitem__(self, index):\n","        'Generates one sample of data'\n","        # get label\n","        X = self.x[index]\n","        Y = self.y[index]\n","        return X, Y\n","    \n","class AE(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.pool = nn.MaxPool2d(kernel_size = 2)\n","        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 3, padding = 1) # 32 x 32 \n","        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 24, kernel_size = 3, padding = 1) \n","        self.conv3 = nn.Conv2d(in_channels = 24, out_channels = 48, kernel_size = 3, padding = 1) \n","        self.conv4 = nn.Conv2d(in_channels = 48, out_channels = 48, kernel_size = 3, padding = 1) \n","        self.conv5 = nn.Conv2d(in_channels = 48, out_channels = 48, kernel_size = 3, padding = 1) \n","        \n","        self.deconv1 = nn.Conv2d(in_channels = 96, out_channels = 48, kernel_size = 3, padding = 1) \n","        self.deconv2 = nn.Conv2d(in_channels = 96, out_channels = 48, kernel_size = 3, padding = 1) \n","        self.deconv3 = nn.Conv2d(in_channels = 72, out_channels = 24, kernel_size = 3, padding = 1) \n","        self.deconv4 = nn.Conv2d(in_channels = 40, out_channels = 16, kernel_size = 3, padding = 1) \n","        self.deconv5 = nn.Conv2d(in_channels = 19, out_channels = 3, kernel_size = 3, padding = 1) \n","        \n","        self.l_relu = nn.LeakyReLU(negative_slope = 0.1)\n","        self.upsample = nn.Upsample(scale_factor = (2, 2))\n","        self.linear = nn.Linear(32, 32)\n","        #self.dropout = nn.Dropout(0.5)\n","        \n","        \n","  \n","    def forward(self, x):\n","        # encode\n","        x1 = self.l_relu(self.conv1(x))\n","        x1 = self.l_relu(self.pool(x1))\n","\n","        x2 = self.l_relu(self.conv2(x1))\n","        x2 = self.l_relu(self.pool(x2))\n","\n","        x3 = self.l_relu(self.conv3(x2))\n","        x3 = self.l_relu(self.pool(x3))\n","\n","        x4 = self.l_relu(self.conv4(x3))\n","        x4 = self.l_relu(self.pool(x4))\n","\n","        x5 = self.l_relu(self.conv5(x4))\n","        #print(x5.shape)\n","\n","        # decode\n","        y1 = torch.cat((x5, x4), dim = 1)\n","        y1 = self.l_relu(self.upsample(y1))\n","        y1 = self.l_relu(self.deconv1(y1))\n","        #print(y1.shape)\n","\n","        y2 = torch.cat((y1, x3), dim = 1)\n","        y2 = self.l_relu(self.upsample(y2))\n","        y2 = self.l_relu(self.deconv2(y2))\n","        #print(y2.shape)\n","\n","        y3 = torch.cat((y2, x2), dim = 1)\n","        y3 = self.l_relu(self.upsample(y3))\n","        y3 = self.l_relu(self.deconv3(y3))\n","        #print(y3.shape)\n","\n","        y4 = torch.cat((y3, x1), dim = 1)\n","        y4 = self.l_relu(self.upsample(y4))\n","        y4 = self.l_relu(self.deconv4(y4))\n","        #print(y4.shape)\n","\n","        y5 = torch.cat((y4, x), dim = 1)\n","        #print(y5.shape)\n","        y5 = self.linear(self.deconv5(y5))\n","        \n","        return y5\n","\n","def plot_3imgs(denoised, ground_truth, noisy_imgs, add_title = ''): #values of the images are in between [0, 255].\n","    plt.subplot(1, 3, 1)\n","    print(noisy_imgs.shape)\n","    plt.imshow(torch.squeeze(noisy_imgs).permute(1, 2, 0).int()) #int since the data has been changed to float for the NN.\n","    plt.title(\"Noisy imgs\")\n","    plt.subplot(1, 3, 2)\n","    plt.imshow(torch.squeeze(ground_truth).permute(1, 2, 0).int())\n","    plt.title(\"Groundtruth\")\n","    plt.subplot(1,3,3)\n","    plt.imshow(torch.squeeze(denoised).permute(1, 2, 0).int())\n","    plt.title(\"Denoised\")\n","    plt.savefig('drive/MyDrive/Colab_Notebooks/DeepL_miniProj/ae-small5/' + Losstype + add_title + '.png', dpi = 300)\n","    plt.show()\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","import torch\n","from datetime import datetime\n","import time\n","\n","\n","\"\"\"\n","noisy_imgs_1, noisy_imgs_2 = torch.load(\"train_data.pkl\")\n","print(\"Training data : \\n noisiy_imgs_1 : \", noisy_imgs_1.shape, \"\\n noisy_imgs_2 : \", noisy_imgs_2.shape)\n","noisy_imgs, clean_imgs = torch.load(\"val_data.pkl\")\n","print(\"Test data : \\n noisiy_imgs : \", noisy_imgs.shape, \"\\n clean_imgs : \", clean_imgs.shape)\n","noisy_imgs_1_reduced, noisy_imgs_2_reduced = noisy_imgs_1[:SIZE], noisy_imgs_2[:SIZE]\n","print(\"Training data reduced : \\n noisiy_imgs_1_reduced : \", noisy_imgs_1_reduced.shape, \"\\n noisy_imgs_2_reduced : \", noisy_imgs_2_reduced.shape)\n","all_noisy_imgs = torch.cat((noisy_imgs_1_reduced, noisy_imgs_2_reduced), dim = 0)\n","print(\"Concatenated training data (reduced) : \\n all_noisy_imgs : \", all_noisy_imgs.shape)\n","\"\"\"\n","\n","SIZE = 50000\n","BATCH_SIZE = 128\n","train_set = Dataset(SIZE)\n","\n","\"\"\"N = 20\n","plt.figure()\n","for i in range(N):\n","    plt.subplot(2, N, 2*i+1)\n","    plt.imshow(train_set.x[i].permute(1, 2, 0).int())\n","    plt.subplot(2, N, 2*i+2)\n","    plt.imshow(train_set.y[i].permute(1, 2, 0).int())\n","plt.show()\"\"\"\n","\n","\n","# Model Initialization\n","model = AE().to(device)\n","  \n","# Validation using MSE Loss function\n","loss_function = nn.MSELoss().to(device)\n","Losstype = \"L1\"\n","Losstype = \"MSE\"\n","  \n","# Using an Adam Optimizer with lr = 0.001\n","optimizer = torch.optim.Adam(model.parameters(),\n","                             lr = 1e-3, betas=(0.9, 0.99))\n","\n","# DataLoader is used to load the dataset \n","# for training\n","loader_1 = torch.utils.data.DataLoader(dataset = train_set,\n","                                     batch_size = BATCH_SIZE,\n","                                     shuffle = True)\n","\n","\n","#OPTIMIZATION\n","epochs = 10\n","outputs = []\n","losses = []\n","start_ = time.time()\n","for epoch in range(epochs):\n","    print(\"epoch : \", epoch + 1)\n","    start = time.time()\n","    Loss = 0\n","    for noisy_imgs_1, noisy_imgs_2 in loader_1:\n","        #print(noisy_imgs_1.shape)\n","        #print(noisy_imgs_2.shape)\n","\n","        #noisy_imgs_1 = noisy_imgs_1.reshape(-1, 32 * 32)\n","        #noisy_imgs_2 = noisy_imgs_2.reshape(-1, 32 * 32)    \n","        # Output of Autoencoder\n","        #print(\"type : \", noisy_imgs_1.dtype)\n","        noisy_imgs_1 = noisy_imgs_1.to(device)\n","        noisy_imgs_2 = noisy_imgs_2.to(device)\n","        reconstructed = model(noisy_imgs_1)\n","            \n","        # Calculating the loss function\n","        loss = loss_function(reconstructed, noisy_imgs_2)\n","            \n","        # The gradients are set to zero,\n","        # the the gradient is computed and stored.\n","        # .step() performs parameter update\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # Storing the losses in a list for plotting\n","        Loss += loss.detach().cpu().numpy()\n","    losses.append(Loss)\n","    print('The epoch took {}s to complete\\n'.format(time.time() - start))\n","    outputs.append((epochs, noisy_imgs_2, reconstructed))\n","  \n","# Defining the Plot Style\n","plt.style.use('fivethirtyeight')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","  \n","# Plotting the last 100 values\n","plt.plot(losses)\n","plt.show()\n","\n","\n","Time = datetime.now().strftime('%m_%d_%Hh_%Mm_%Ss')\n","\n","PATH = \"drive/MyDrive/Colab_Notebooks/DeepL_miniProj/ae-small5/ae_\" + Losstype + Time + \".pth\" # so that we don't overwrite files\n","torch.save(model.state_dict(), PATH)\n","\n","print('Finished training after {}.'.format(time.time() - start_))\n","print('\\n\\n\\n')\n","print('------------------------------------------------')\n","\n","\n","#model = AE()\n","#time = '04_27_13h_14m_41s' # to be filled according to the job we want to load\n","#PATH = \"./test1/project1_1_\" + time + \".pth\"\n","#model.load_state_dict(torch.load(PATH))\n","\n","\n","print(\"validation\")\n","print('\\n')\n","SIZE = 1000\n","BATCH_SIZE = 1\n","test_set = Dataset(SIZE, train = False)\n","\n","\"\"\"plt.subplot(2, 1, 1)\n","plt.imshow(test_set.x[-1].permute(1, 2, 0).int())\n","plt.subplot(2, 1, 2)\n","plt.imshow(test_set.y[-1].permute(1, 2, 0).int())\n","plt.show()\"\"\"\n","\n","loader_2 = torch.utils.data.DataLoader(dataset = test_set,\n","                                     batch_size = BATCH_SIZE,\n","                                     shuffle = False)\n","\n","PSNR = torch.empty(size = (1, SIZE))\n","i = 0\n","for noisy_imgs, ground_truth in loader_2:\n","    noisy_imgs = noisy_imgs.to(device)\n","    ground_truth = ground_truth.to(device)\n","    denoised = model(noisy_imgs)\n","    Psnr = psnr(denoised.cpu() / 255, ground_truth.cpu() / 255)\n","    PSNR[0, i] = Psnr\n","    #if Psnr > 32:\n","     #   plot_3imgs(denoised, ground_truth, noisy_imgs, add_title = 'good' + str(i))\n","    #if Psnr < 20:\n","     #   plot_3imgs(denoised, ground_truth, noisy_imgs, add_title = 'bad' + str(i))\n","    i += 1\n","\n","plot_3imgs(denoised.cpu(), ground_truth.cpu(), noisy_imgs.cpu(), add_title = Time)\n","\n","print(\"PSNR mean : \", torch.mean(PSNR).item(), \" dB\")\n","plt.style.use('fivethirtyeight')\n","plt.ylabel('PSNR')\n","plt.plot(PSNR[0,:].detach().numpy())\n","plt.savefig('drive/MyDrive/Colab_Notebooks/DeepL_miniProj/ae-small5/psnr_' + Losstype + Time + '.png', dpi = 300)\n","plt.show()"]},{"cell_type":"code","source":[""],"metadata":{"id":"m2tnqAG5ci5X"},"execution_count":null,"outputs":[]}]}