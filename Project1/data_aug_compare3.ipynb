{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Training data : \n",
      " noisy_imgs_1 :  torch.Size([50000, 3, 32, 32]) \n",
      " noisy_imgs_2 :  torch.Size([50000, 3, 32, 32])\n",
      "Data reduced : \n",
      " noisy_imgs_1_reduced :  torch.Size([50000, 3, 32, 32]) \n",
      " noisy_imgs_2_reduced :  torch.Size([50000, 3, 32, 32])\n",
      "Type :  torch.uint8\n",
      "With data augmentation : transform.\n",
      "Training data : \n",
      " noisy_imgs_1 :  torch.Size([50000, 3, 32, 32]) \n",
      " noisy_imgs_2 :  torch.Size([50000, 3, 32, 32])\n",
      "Data reduced : \n",
      " noisy_imgs_1_reduced :  torch.Size([50000, 3, 32, 32]) \n",
      " noisy_imgs_2_reduced :  torch.Size([50000, 3, 32, 32])\n",
      "Type :  torch.uint8\n",
      "Training with augmentation : \n",
      "epoch :  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Anya48/Documents/GitHub/Deep_learning_mini_projects/Project1/data_aug_compare3.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 211>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Anya48/Documents/GitHub/Deep_learning_mini_projects/Project1/data_aug_compare3.ipynb#ch0000000?line=227'>228</a>\u001b[0m \u001b[39m# The gradients are set to zero,\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Anya48/Documents/GitHub/Deep_learning_mini_projects/Project1/data_aug_compare3.ipynb#ch0000000?line=228'>229</a>\u001b[0m \u001b[39m# the the gradient is computed and stored.\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Anya48/Documents/GitHub/Deep_learning_mini_projects/Project1/data_aug_compare3.ipynb#ch0000000?line=229'>230</a>\u001b[0m \u001b[39m# .step() performs parameter update\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Anya48/Documents/GitHub/Deep_learning_mini_projects/Project1/data_aug_compare3.ipynb#ch0000000?line=230'>231</a>\u001b[0m optimizer_aug\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/Anya48/Documents/GitHub/Deep_learning_mini_projects/Project1/data_aug_compare3.ipynb#ch0000000?line=231'>232</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Anya48/Documents/GitHub/Deep_learning_mini_projects/Project1/data_aug_compare3.ipynb#ch0000000?line=232'>233</a>\u001b[0m optimizer_aug\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Anya48/Documents/GitHub/Deep_learning_mini_projects/Project1/data_aug_compare3.ipynb#ch0000000?line=233'>234</a>\u001b[0m \u001b[39m# Storing the losses in a list for plotting\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/Anya48/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/Anya48/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///Users/Anya48/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///Users/Anya48/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/Anya48/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///Users/Anya48/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///Users/Anya48/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/Anya48/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/Anya48/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///Users/Anya48/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///Users/Anya48/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///Users/Anya48/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "Here we explore data augmentation. TERMINER D'Ã©CRIRE ET FAIRE RUN.\n",
    "\"\"\"\n",
    "\n",
    "class AE_small5(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 3, padding = 1) # 32 x 32 \n",
    "        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 24, kernel_size = 3, padding = 1) \n",
    "        self.conv3 = nn.Conv2d(in_channels = 24, out_channels = 48, kernel_size = 3, padding = 1) \n",
    "        self.conv4 = nn.Conv2d(in_channels = 48, out_channels = 48, kernel_size = 3, padding = 1) \n",
    "        self.conv5 = nn.Conv2d(in_channels = 48, out_channels = 48, kernel_size = 3, padding = 1) \n",
    "        \n",
    "        self.deconv1 = nn.Conv2d(in_channels = 96, out_channels = 48, kernel_size = 3, padding = 1) \n",
    "        self.deconv2 = nn.Conv2d(in_channels = 96, out_channels = 48, kernel_size = 3, padding = 1) \n",
    "        self.deconv3 = nn.Conv2d(in_channels = 72, out_channels = 24, kernel_size = 3, padding = 1) \n",
    "        self.deconv4 = nn.Conv2d(in_channels = 40, out_channels = 16, kernel_size = 3, padding = 1) \n",
    "        self.deconv5 = nn.Conv2d(in_channels = 19, out_channels = 3, kernel_size = 3, padding = 1) \n",
    "        \n",
    "        self.l_relu = nn.LeakyReLU(negative_slope = 0.1)\n",
    "        self.upsample = nn.Upsample(scale_factor = (2, 2))\n",
    "        self.linear = nn.Linear(32, 32)\n",
    "        #self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        \n",
    "  \n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        x1 = self.l_relu(self.conv1(x))\n",
    "        x1 = self.l_relu(self.pool(x1))\n",
    "\n",
    "        x2 = self.l_relu(self.conv2(x1))\n",
    "        x2 = self.l_relu(self.pool(x2))\n",
    "\n",
    "        x3 = self.l_relu(self.conv3(x2))\n",
    "        x3 = self.l_relu(self.pool(x3))\n",
    "\n",
    "        x4 = self.l_relu(self.conv4(x3))\n",
    "        x4 = self.l_relu(self.pool(x4))\n",
    "\n",
    "        x5 = self.l_relu(self.conv5(x4))\n",
    "        #print(x5.shape)\n",
    "\n",
    "        # decode\n",
    "        y1 = torch.cat((x5, x4), dim = 1)\n",
    "        y1 = self.l_relu(self.upsample(y1))\n",
    "        y1 = self.l_relu(self.deconv1(y1))\n",
    "        #print(y1.shape)\n",
    "\n",
    "        y2 = torch.cat((y1, x3), dim = 1)\n",
    "        y2 = self.l_relu(self.upsample(y2))\n",
    "        y2 = self.l_relu(self.deconv2(y2))\n",
    "        #print(y2.shape)\n",
    "\n",
    "        y3 = torch.cat((y2, x2), dim = 1)\n",
    "        y3 = self.l_relu(self.upsample(y3))\n",
    "        y3 = self.l_relu(self.deconv3(y3))\n",
    "        #print(y3.shape)\n",
    "\n",
    "        y4 = torch.cat((y3, x1), dim = 1)\n",
    "        y4 = self.l_relu(self.upsample(y4))\n",
    "        y4 = self.l_relu(self.deconv4(y4))\n",
    "        #print(y4.shape)\n",
    "\n",
    "        y5 = torch.cat((y4, x), dim = 1)\n",
    "        #print(y5.shape)\n",
    "        y5 = self.linear(self.deconv5(y5))\n",
    "        \n",
    "        return y5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, SIZE, train = True, transform = None, switch_pixels = None):\n",
    "        'Initialization'\n",
    "        if train: \n",
    "            if SIZE > 50000: \n",
    "                print(\"SIZE is to big. It is set to SIZE = 50000.\")\n",
    "                SIZE = 50000\n",
    "            x, y = torch.load(\"train_data.pkl\")\n",
    "            print(\"Training data : \\n noisy_imgs_1 : \", x.shape, \"\\n noisy_imgs_2 : \", y.shape)\n",
    "        else : \n",
    "            if SIZE > 1000:\n",
    "                print(\"SIZE is to big. It is set to SIZE = 1000.\")\n",
    "                SIZE = 1000\n",
    "            x, y = torch.load(\"val_data.pkl\")\n",
    "            print(\"Test data : \\n noisy_imgs : \", x.shape, \"\\n clean_imgs : \", y.shape)\n",
    "        x, y = x[:SIZE], y[:SIZE]\n",
    "        print(\"Data reduced : \\n noisy_imgs_1_reduced : \", x.shape, \"\\n noisy_imgs_2_reduced : \", y.shape)\n",
    "        print(\"Type : \", x.dtype)\n",
    "        if transform != None :\n",
    "            print(\"With data augmentation : transform.\")\n",
    "        if switch_pixels != None :\n",
    "            print(\"With data augmentation : switch pixels with n_max = \", switch_pixels[0], \" and p = \", switch_pixels[1])\n",
    "        self.x = x.float()\n",
    "        self.y = y.float()\n",
    "        self.transform = transform\n",
    "        self.switch_pixels = switch_pixels\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.x)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # get label\n",
    "        X_trans = self.x[index]\n",
    "        Y_trans= self.y[index]\n",
    "\n",
    "        seed = torch.randint(2147483647,(1,1)) # make a seed with generator \n",
    "        torch.manual_seed(seed.item()) # set the random seed for transforms\n",
    "        if self.transform is not None:\n",
    "            X_trans = self.transform(X_trans)\n",
    "\n",
    "        torch.manual_seed(seed.item()) # set the random seed for transforms\n",
    "        if self.transform is not None:\n",
    "            Y_trans = self.transform(Y_trans)  \n",
    "        \n",
    "        torch.manual_seed(seed.item())\n",
    "        if self.switch_pixels is not None:\n",
    "            n_max, p = self.switch_pixels\n",
    "            # n_max : maximum number of pixels that might switch. \n",
    "            # p : prob that the pixels are switched.\n",
    "            if torch.rand((1,1)) < p:\n",
    "                if n_max<50 :\n",
    "                    n_max = 51\n",
    "                # n : number of switched pixels, random in between 50 and n_max (not included)\n",
    "                n = torch.randint(low = 50, high = n_max, size = (1,1))\n",
    "                # index : random index of the n pixels that will be switched.\n",
    "                index = torch.randint(low=0, high = X_trans.shape[1], size = (n,2))\n",
    "                i,j = index[:, 0], index[:, 1]\n",
    "                v_x = Y_trans[:, i, j].copy()\n",
    "                v_y = X_trans[:, i, j].copy()\n",
    "\n",
    "                X_trans[:, i, j] = v_x\n",
    "                Y_trans[:, i, j] = v_y\n",
    "\n",
    "        return X_trans, Y_trans\n",
    "\n",
    "\n",
    "class MyRotateTransform(torch.nn.Module):\n",
    "    def __init__(self, angles, p=0.8):\n",
    "        self.angles = angles\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, x):\n",
    "        #angle = random.choice(self.angles)\n",
    "        if torch.rand((1,1)) < self.p:\n",
    "            rand_index = torch.randint(low=0, high = len(self.angles), size = (1,1))\n",
    "            angle = self.angles[rand_index]\n",
    "        else : angle = 0\n",
    "        return TF.rotate(x, angle)\n",
    "\n",
    "\n",
    "transform2 = transforms.RandomApply(torch.nn.ModuleList([\n",
    "    # horizontal flip with probability p \n",
    "    transforms.RandomHorizontalFlip(p=0.8),\n",
    "    # vertical flip with probability p \n",
    "    transforms.RandomVerticalFlip(p=0.8),\n",
    "    # rotation of angle in angles with probility p\n",
    "    MyRotateTransform(angles = [90, 180, 270], p=0.8)]),\n",
    "    p=0.8) #randomly transform images with probability p\n",
    "\n",
    "\n",
    "SIZE = 50000\n",
    "BATCH_SIZE = 128\n",
    "n_max = 250 #about a fourth of the total number of pixels in a image.\n",
    "p = 0.5\n",
    "train_set_aug = Dataset(SIZE, transform=transform2)\n",
    "train_set = Dataset(SIZE)\n",
    "\n",
    "\n",
    "# Model Initialization\n",
    "model = AE_small5()\n",
    "model_aug = AE_small5()\n",
    "model_aug.load_state_dict(model.state_dict()) \n",
    "  \n",
    "# Validation using MSE Loss function\n",
    "loss_function = nn.MSELoss().to(device)\n",
    "  \n",
    "# Using an Adam Optimizer with lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 1e-3, betas=(0.9, 0.99))\n",
    "optimizer_aug = torch.optim.Adam(model_aug.parameters(),\n",
    "                             lr = 1e-3, betas=(0.9, 0.99))                            \n",
    "\n",
    "# DataLoader is used to load the dataset \n",
    "# for training\n",
    "loader_1 = torch.utils.data.DataLoader(dataset = train_set,\n",
    "                                     batch_size = BATCH_SIZE,\n",
    "                                     shuffle = True)\n",
    "loader_aug = torch.utils.data.DataLoader(dataset = train_set_aug,\n",
    "                                     batch_size = BATCH_SIZE,\n",
    "                                     shuffle = True)                                    \n",
    "\n",
    "#OPTIMIZATION\n",
    "epochs = 10\n",
    "outputs_aug = []\n",
    "losses_aug = []\n",
    "print(\"Training with augmentation : \")\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch : \", epoch)\n",
    "    for noisy_imgs_1, noisy_imgs_2 in loader_aug:\n",
    "        #print(noisy_imgs_1.shape)\n",
    "        #print(noisy_imgs_2.shape)\n",
    "\n",
    "        #noisy_imgs_1 = noisy_imgs_1.reshape(-1, 32 * 32)\n",
    "        #noisy_imgs_2 = noisy_imgs_2.reshape(-1, 32 * 32)    \n",
    "        # Output of Autoencoder\n",
    "        #print(\"type : \", noisy_imgs_1.dtype)\n",
    "        noisy_imgs_1 = noisy_imgs_1.to(device)\n",
    "        noisy_imgs_2 = noisy_imgs_2.to(device)\n",
    "        reconstructed = model_aug(noisy_imgs_1)\n",
    "            \n",
    "        # Calculating the loss function\n",
    "        loss = loss_function(reconstructed, noisy_imgs_2)\n",
    "            \n",
    "        # The gradients are set to zero,\n",
    "        # the the gradient is computed and stored.\n",
    "        # .step() performs parameter update\n",
    "        optimizer_aug.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_aug.step()\n",
    "        # Storing the losses in a list for plotting\n",
    "        losses_aug.append(loss.detach().numpy())\n",
    "    outputs_aug.append((epochs, noisy_imgs_2, reconstructed))\n",
    "\n",
    "\n",
    "outputs = []\n",
    "losses = []\n",
    "print(\"Training without augmentation : \")\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch : \", epoch)\n",
    "    for noisy_imgs_1, noisy_imgs_2 in loader_1:\n",
    "        # Output of Autoencoder\n",
    "        #print(\"type : \", noisy_imgs_1.dtype)\n",
    "        noisy_imgs_1 = noisy_imgs_1.to(device)\n",
    "        noisy_imgs_2 = noisy_imgs_2.to(device)\n",
    "        reconstructed = model(noisy_imgs_1)\n",
    "            \n",
    "        # Calculating the loss function\n",
    "        loss = loss_function(reconstructed, noisy_imgs_2)\n",
    "            \n",
    "        # The gradients are set to zero,\n",
    "        # the the gradient is computed and stored.\n",
    "        # .step() performs parameter update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Storing the losses in a list for plotting\n",
    "        losses.append(loss.detach().numpy())\n",
    "    outputs.append((epochs, noisy_imgs_2, reconstructed))\n",
    "\n",
    "# Defining the Plot Style\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "  \n",
    "# Plotting the last 100 values\n",
    "plt.plot(losses[-100:])\n",
    "plt.plot(losses_aug[-100:])\n",
    "plt.legend([\"Without augmentation\", \"With augmentation\"])\n",
    "plt.savefig(\"./Data_aug/AE_small5_losses\")\n",
    "plt.show()\n",
    "\n",
    "PATH = \"./Data_aug/AE_small5_model.pth\"\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "\n",
    "PATH = \"./Data_aug/AE_small5_model_aug.pth\"\n",
    "torch.save(model_aug.state_dict(), PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6aa7871422cbf9296a09eca5272ae12f42feac121f15077f0682f5d4affb8114"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
